{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dataset Generation for News Headlines Mood Analysis\n",
    "\n",
    "This notebook performs the following tasks:\n",
    "\n",
    "1. Loads a dataset of news headlines using the Hugging Face datasets library\n",
    "2. Samples 30,000 headlines randomly from the dataset\n",
    "3. Generates JSON files containing API requests to evaluate headline mood impacts using GPT-4.1:\n",
    "   - Splits headlines into 2 batches of 15,000 each\n",
    "   - Creates requests asking for mood impact ratings between 1-10\n",
    "4. Processes the API response files to extract mood ratings:\n",
    "   - Normalizes ratings to 0-1 scale\n",
    "   - Validates rating responses\n",
    "   - Creates separate DataFrames for ratings and validation flags\n",
    "\n",
    "The generated dataset will be used for training a model to assess the emotional impact of news headlines."
   ],
   "id": "652c0130ebe80b7f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "load_dotenv()\n",
    "\n",
    "huff_post = load_dataset(os.getenv(\"DATASET\"))\n",
    "huff_post = pd.DataFrame(huff_post['test'])\n",
    "\n",
    "headlines = huff_post[os.getenv(\"HEADLINE_COLUMN\")].sample(n=30000)"
   ],
   "id": "11e241be58d7e026"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Rating Scale Choice (1-10)\n",
    "GPT-4.1 demonstrated more consistent and reliable performance when asked to provide ratings on a 1-10 scale compared to normalized values (0-1).\n",
    "\n",
    "### Batch Processing Implementation\n",
    "The API has limitations on batch request sizes, necessitating splitting our 30,000 headlines into smaller chunks:\n",
    "1. Each batch contains 15,000 headlines to stay within API limits\n",
    "2. Multiple smaller batches improve error handling and recovery\n",
    "3. Parallel processing of batches can potentially reduce total processing time"
   ],
   "id": "5e2b56b737627ae2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def generate_batch(batch_id: int, data: any) -> None:\n",
    "    \"\"\"\n",
    "    Generates a batch file containing JSON lines for API requests. Each request\n",
    "    is tailored for evaluating the mood impact of a given headline.\n",
    "\n",
    "    :param batch_id: The unique identifier for the batch being generated.\n",
    "    :param data: A list of headlines to process and include in the batch file.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    with open(f'openai/headlines_batch_{batch_id}.jsonl', 'w') as f:\n",
    "        for i, headline in enumerate(data, 1):\n",
    "            request_data = {\n",
    "                \"custom_id\": f\"request-{i}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": \"gpt-4.1\",\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": \"How much would this headline negatively impact a user's mood? Only output a number between 1 and 10.\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": headline\n",
    "                        }\n",
    "                    ],\n",
    "                    \"max_tokens\": 1000\n",
    "                }\n",
    "            }\n",
    "            f.write(json.dumps(request_data) + '\\n')"
   ],
   "id": "2d2826a4dc0e7170"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "generate_batch(1, headlines.iloc[:15000])\n",
    "generate_batch(2, headlines.iloc[15000:])"
   ],
   "id": "2e40b0a500680ccc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### GPT Data Validation\n",
    "\n",
    "The validation process for GPT-generated ratings includes:\n",
    "\n",
    "1. Checking if the response is a valid numeric value\n",
    "2. Ensuring ratings fall within expected 1-10 range \n",
    "3. Normalizing ratings to 0-1 scale\n",
    "4. Flagging invalid responses for quality control"
   ],
   "id": "12d1c91a10774e29"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def extract_ratings_from_batch_file(filepath: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Extract ratings and validation results from a batch file containing JSON lines.\n",
    "\n",
    "    This function reads a file containing JSON objects in each line, processes the\n",
    "    `content` field in each entry, and extracts ratings and their validity status.\n",
    "    Ratings are normalised by dividing by 10. Invalid ratings are flagged as not\n",
    "    valid.\n",
    "\n",
    "    :param filepath: The path to the file containing batch JSON lines.\n",
    "    :type filepath: str\n",
    "    :return: A tuple containing two pandas DataFrames:\n",
    "             - One for ratings with a column named 'ratings'.\n",
    "             - Another for validation flags with a column named 'validation'.\n",
    "    :rtype: tuple\n",
    "    \"\"\"\n",
    "    ratings = []\n",
    "    validation = []\n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            batch_response = json.loads(line.strip())\n",
    "            content = batch_response['response']['body']['choices'][0]['message']['content']\n",
    "\n",
    "            rating = 0\n",
    "            validity = True\n",
    "            if content.isdigit():\n",
    "                rating = int(content) / 10\n",
    "                if rating > 1:\n",
    "                    validity = False\n",
    "            else:\n",
    "                validity = False\n",
    "\n",
    "            ratings.append(rating)\n",
    "            validation.append(validity)\n",
    "\n",
    "    return pd.DataFrame({'ratings': ratings}), pd.DataFrame({'validation': validation})"
   ],
   "id": "c4a07c28564896d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ratings_1, validation_1 = extract_ratings_from_batch_file('../data/openai/headlines_batch_1_output.json')\n",
    "ratings_2, validation_2 = extract_ratings_from_batch_file('../data/openai/headlines_batch_2_output.json')"
   ],
   "id": "5a1c60c254cd5647"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "headlines.reset_index(drop=True, inplace=True)\n",
    "\n",
    "all_ratings = pd.concat([ratings_1, ratings_2], axis=0, ignore_index=True)\n",
    "all_validation = pd.concat([validation_1, validation_2], axis=0, ignore_index=True)\n",
    "all_data = pd.concat([headlines, all_ratings], axis=1)"
   ],
   "id": "32d229b0272185b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = all_data[all_validation['validation']]\n",
    "data.columns = ['text', 'labels']\n",
    "data.to_csv('headline_data.csv', index=False)"
   ],
   "id": "87e3ac534a5e0b38"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
